# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oRowbocIpv0otrQRliON31g9OYY2tFUi

**Downloading dataset from Kaggle**
"""

import os
os.environ['KAGGLE_USERNAME'] = "samcrochet" # username from the json file
os.environ['KAGGLE_KEY'] = "abdc46a2e40c833d95208db44af90cae" # key from the json file
!kaggle datasets download -d samcrochet/15dogsdataset
!unzip -q 15dogsdataset.zip
!rm -rf 15dogsdataset.zip

"""**Installing requirements from file**"""

!wget https://raw.github.ncsu.edu/sdcroche/P29-CSC422-Project/master/requirements.txt?token=AAABYIKHMN666UFBEHMUSX26VMKQO -O requirements.txt
!pip install -q -r requirements.txt


import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.regularizers import l2
import os
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import split_folders
import datetime
from sklearn.metrics import confusion_matrix

"""**Split dataset into Train, Validate, Test**"""

split_folders.ratio("images/", output="split-data", seed=1337, ratio=(.7, .2, .1)) # default values

"""**Define Hyperparameters**"""

IMG_HEIGHT = 256 
IMG_WIDTH = 256
MODEL_FILENAME = "dog_cnn_model_COLOR.h5"
MODEL_FILENAME_G = "dog_cnn_model_GRAYSCALE.h5"

BATCH_SIZE = 32
EPOCHS = 60
LEARNING_RATE = 0.0005

SOURCE_PATH = "split-data/"

"""**Importing classnames to train and validate on**"""

class_names = sorted([name for name in os.listdir('./images/') if os.path.isdir(os.path.join("./images/",name))])
print(len(class_names),class_names)

PATH = os.path.dirname("./" + SOURCE_PATH)
train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'val')

num_training = 0 
for i in class_names: 
    num_training += len(os.listdir(os.path.join(train_dir,i)))
print("total training images over "+ str(len(class_names))+ " classes: " + str(num_training))

num_validation = 0 
for i in class_names: 
    num_validation += len(os.listdir(os.path.join(validation_dir,i)))
print("total validaiton images over "+ str(len(class_names))+ " classes: " + str(num_validation))

"""**Function to show batch of training data**"""

def show_batch(image_batch, label_batch, GRAYSCALE):
    plt.figure(figsize=(10, 10))
    for n in range(9):
        ax = plt.subplot(3, 3, n + 1)

        if GRAYSCALE: 
            plt.imshow(np.squeeze(image_batch[n], axis=2))
        else:
            plt.imshow(image_batch[n])

        idx = ([i for i, val in enumerate((label_batch[n] == 1)) if val])[0]
        plt.title(class_names[idx])
        plt.axis('off')
    plt.show()
    plt.savefig("batch_sample_GRAYSCALE="+str(GRAYSCALE))

"""**Function to evaluate training over time with plot**"""

def evaluate_training(history, GRAYSCALE): 
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']

    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs_range = range(EPOCHS)

    plt.figure(figsize=(8, 8))
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, acc, label='Training Accuracy')
    plt.plot(epochs_range, val_acc, label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label='Training Loss')
    plt.plot(epochs_range, val_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.show()
    plt.savefig("model_train_graph_GRAYSCALE="+str(GRAYSCALE))

"""**Training function**"""

def train_model(GRAYSCALE): 
    train_image_generator = ImageDataGenerator( rescale=1. / 255,
                                                rotation_range=10, 
                                                horizontal_flip=True, 
                                                width_shift_range=[-30,30],
                                                brightness_range=[0.7,1.0])

    validation_image_generator = ImageDataGenerator(rescale=1. / 255,
                                                    rotation_range=10, 
                                                    horizontal_flip=True, 
                                                    width_shift_range=[-30,30],
                                                    brightness_range=[0.7,1.0])
    
    COLOR_MODE = ""
    DEPTH = 0

    if GRAYSCALE: 
        COLOR_MODE = 'grayscale'
        DEPTH = 1
    else: 
        COLOR_MODE = 'rgb'
        DEPTH = 3

    train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                               directory=train_dir,
                                                               shuffle=True,
                                                               target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                               class_mode='categorical',
                                                               color_mode=COLOR_MODE)

    val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                                  directory=validation_dir,
                                                                  target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                                  class_mode='categorical',
                                                                  color_mode=COLOR_MODE)

    image_batch, label_batch = next(train_data_gen)
    show_batch(image_batch, label_batch, GRAYSCALE)  

  

    model = Sequential()
    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,DEPTH)))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(Flatten())
    model.add(Dense(units = 256, activation = "relu"))
    model.add(Dense(units = 128, activation = "relu"))
    model.add(Dense(units = 64, activation = "relu"))
    model.add(Dense(len(class_names), activation='softmax'))

    model.compile(optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE),
                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])

    # Output summary of the model
    model.summary()

    log_dir="logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

    history = model.fit(train_data_gen,
                        epochs=EPOCHS,
                        steps_per_epoch=num_training // BATCH_SIZE,
                        validation_data=val_data_gen,
                        validation_steps=num_validation // BATCH_SIZE, 
                        callbacks=[tensorboard_callback])
    if GRAYSCALE: 
        model.save(MODEL_FILENAME_G)
    else: 
        model.save(MODEL_FILENAME)

    return history

"""**Model Evaluaiton after Training**"""

def test_model(GRAYSCALE): 
    PATH = os.path.dirname(SOURCE_PATH)
    test_dir = os.path.join(PATH, 'test')
    
    model = None
    if GRAYSCALE: 
        model = load_model(MODEL_FILENAME_G)
    else: 
        model = load_model(MODEL_FILENAME)


    test_image_generator = ImageDataGenerator(rescale=1. / 255)

    if GRAYSCALE: 
        COLOR_MODE = 'grayscale'
    else: 
        COLOR_MODE = 'rgb'

    test_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                             directory=test_dir,
                                                             target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                             class_mode='categorical',
                                                             color_mode=COLOR_MODE,
                                                             classes=class_names)
    
    per = np.random.permutation(test_data_gen.n)
    test_data_gen.index_array = per
    classes = test_data_gen.classes[per]

    predictions = model.predict(test_data_gen)
    results = model.evaluate(test_data_gen, verbose=1)

    predictions = np.argmax(predictions,axis=1)

    for name, value in zip(model.metrics_names, results):
      print(name, ': ', value)
    print()

    for i in range(0,len(class_names)): 
      print(i,class_names[i])

    cm = confusion_matrix(classes, predictions)
    plt.figure(figsize=(10,10))
    sns.heatmap(cm, annot=True, fmt="d", xticklabels=class_names, yticklabels=class_names)
    plt.title('Confusion matrix')
    plt.ylabel('Actual label')
    plt.xlabel('Predicted label')

    return

"""**MAIN: Code to run training and evaluation on grayscale and color images**"""

GRAYSCALE = False
train_hist = train_model(GRAYSCALE)
evaluate_training(train_hist, GRAYSCALE)
test_model(GRAYSCALE)

"""**Push Logs to TensorBoard**"""

# ! tensorboard dev upload --logdir ./logs \
#     --name "CSC 422 CNN Dog Project " \
#     --description "Training values"
# !rm -rf ./logs/